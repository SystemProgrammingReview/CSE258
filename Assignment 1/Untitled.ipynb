{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from collections import defaultdict, OrderedDict\n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def readJson(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return df\n",
    "\n",
    "df = readJson('assignment1/train.json.gz')\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(df)\n",
    "\n",
    "trainingData = [df[x] for x in range(0,150000)]\n",
    "validationData = [df[x] for x in range(150000,200000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userIndex = {}\n",
    "users = []\n",
    "userToItem = defaultdict(list)\n",
    "itemIndex = {}\n",
    "items = []\n",
    "itemToUser = defaultdict(list)\n",
    "i,j = 0,0\n",
    "trainLines,validationLines = [],[]\n",
    "ID = 0\n",
    "for data in trainingData:\n",
    "    userToItem[data['reviewerID']].append(data['itemID'])\n",
    "    itemToUser[data['itemID']].append(data['reviewerID'])\n",
    "    if data['reviewerID'] not in userIndex:\n",
    "        userIndex[data['reviewerID']] = i\n",
    "        users.append(data['reviewerID'])\n",
    "        i += 1\n",
    "    if data['itemID'] not in itemIndex:\n",
    "        itemIndex[data['itemID']] = j\n",
    "        items.append(data['itemID'])\n",
    "        j += 1\n",
    "    trainLines.append(str(ID)+','+str(userIndex[data['reviewerID']])+','+str(itemIndex[data['itemID']])+','+str(int(data['rating'])))\n",
    "    ID += 1\n",
    "\n",
    "for data in validationData:\n",
    "    userToItem[data['reviewerID']].append(data['itemID'])\n",
    "    itemToUser[data['itemID']].append(data['reviewerID'])\n",
    "    if data['reviewerID'] not in userIndex:\n",
    "        userIndex[data['reviewerID']] = i\n",
    "        users.append(data['reviewerID'])\n",
    "        i += 1\n",
    "    if data['itemID'] not in itemIndex:\n",
    "        itemIndex[data['itemID']] = j\n",
    "        items.append(data['itemID'])\n",
    "        j += 1\n",
    "    validationLines.append(str(ID)+','+str(userIndex[data['reviewerID']])+','+str(itemIndex[data['itemID']]))\n",
    "    ID += 1\n",
    "\n",
    "# Rui = np.zeros((len(users), len(items)))\n",
    "# for data in trainingData:\n",
    "#     Rui[userIndex[data['reviewerID']]][itemIndex[data['itemID']]] = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.txt', mode='wt') as myfile:\n",
    "    myfile.write('ID,user,movie,rating\\n')\n",
    "    myfile.write('\\n'.join(trainLines))\n",
    "with open('validation.txt', mode='wt') as myfile:\n",
    "    myfile.write('ID,user,movie,rating\\n')\n",
    "    myfile.write('\\n'.join(validationLines ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "pd.options.display.max_columns = 10 \n",
    "pd.options.display.width = 134\n",
    "pd.options.display.max_rows = 20\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "train = pd.read_csv('train.txt')\n",
    "test = pd.read_csv('validation.txt')\n",
    "matrix = pd.concat([train,test]).pivot('user','movie','rating')\n",
    "movie_means = matrix.mean()\n",
    "user_means = matrix.mean(axis=1)\n",
    "mzm = matrix-movie_means\n",
    "# mz = mzm.fillna(0)\n",
    "# mask = -mzm.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e7f382c12f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmzm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmzm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\quant\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m                      \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m                                   \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m                                   downcast=downcast, **kwargs)\n\u001b[0m\u001b[1;32m   2763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shift'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\quant\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   3182\u001b[0m                 new_data = self._data.fillna(value=value, limit=limit,\n\u001b[1;32m   3183\u001b[0m                                              \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3184\u001b[0;31m                                              downcast=downcast)\n\u001b[0m\u001b[1;32m   3185\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3186\u001b[0m                 \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\quant\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   2930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2932\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fillna'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\quant\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, raw, **kwargs)\u001b[0m\n\u001b[1;32m   2888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\quant\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, limit, inplace, downcast, mgr)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_coerce_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             blocks = [b.make_block(values=self._try_coerce_result(b.values))\n\u001b[1;32m    356\u001b[0m                       for b in blocks]\n",
      "\u001b[0;32mC:\\Users\\quant\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mputmask\u001b[0;34m(self, mask, new, align, inplace, axis, transpose, mgr)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \"\"\"\n\u001b[1;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reindex_axis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mz = mzm.fillna(0)\n",
    "mask = -mzm.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here here2"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "mse_last = 999\n",
    "while iteration<10:\n",
    "    iteration += 1\n",
    "    svd = TruncatedSVD(n_components=15,random_state=42)\n",
    "    svd.fit(mz)\n",
    "    print 'here',\n",
    "    mzsvd = pd.DataFrame(svd.inverse_transform(svd.transform(mz)),columns=mz.columns,index=mz.index)\n",
    "    print 'here2',\n",
    "#     mse = mean_squared_error(mzsvd[mask].fillna(0),mzm[mask].fillna(0))\n",
    "#     print('%i %.5f %.5f'%(iteration,mse,mse_last-mse))\n",
    "    mzsvd[mask] = mzm[mask]\n",
    "\n",
    "    mz = mzsvd\n",
    "#     if mse_last-mse<0.00001: break\n",
    "#     mse_last = mse\n",
    "\n",
    "# m = mz+movie_means\n",
    "# m = m.clip(lower=1,upper=5)\n",
    "\n",
    "# test['rating'] = test.apply(lambda x:m[m.index==x.user][x.movie].values[0],axis=1)\n",
    "\n",
    "# # There are some movies who did not have enough info to make prediction, so just used average value for user\n",
    "# missing = np.where(test.rating.isnull())[0]\n",
    "# test.ix[missing,'rating'] = user_means[test.loc[missing].user].values\n",
    "\n",
    "# test.to_csv('submission.csv',index=False,columns=['ID','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in open(\"assignment1/pairs_Rating.txt\"):\n",
    "    if line.startswith(\"userID\"):\n",
    "        continue\n",
    "    user,item = line.strip().split('-')\n",
    "    if user not in userIndex:\n",
    "        userIndex[user] = i\n",
    "        i += 1\n",
    "    if item not in itemIndex:\n",
    "        itemIndex[item] = j\n",
    "    lines.append(str(userIndex[user])+','+ str(itemIndex[item]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
