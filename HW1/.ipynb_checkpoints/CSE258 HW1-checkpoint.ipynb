{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE258 HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse255/data/beer/beer_50000.json\"))\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train a predictor with linear regression as below:\n",
    "\n",
    "$'review/overall' = \\theta_0 + \\theta_1 * 'year'$\n",
    "\n",
    "The fitted values are $\\theta_0 = -3.917e+01, \\theta_1 = 2.1438e-02$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = [[1,i['review/timeStruct']['year']] for i in data]\n",
    "\n",
    "y = [i['review/overall'] for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.91707489e+01   2.14379786e-02]\n",
      "[ 0.49004382]\n"
     ]
    }
   ],
   "source": [
    "result1 = np.linalg.lstsq(x1,y)\n",
    "print result1[0]\n",
    "MSE1 = result1[1]/50000\n",
    "print MSE1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Q2\n",
    "Then we use a second-order polynomial predictor instead of linear one:\n",
    "\n",
    "$'review/overall' = \\theta_0 + \\theta_1 * year + \\theta_2 * year ^ 2$\n",
    "\n",
    "The MSE in Q1 is 0.49004382. While here we have MSE as 0.49003734, which is only little better. Actually, 'review/overall' can depends little on one-dimension feature, 'year', since we see that the beers in the same 'year' may varies a lot in 'review/overall'. So our improvement is little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2= []\n",
    "for feat in x1:\n",
    "    newFeat = feat[:]\n",
    "    newFeat.append(feat[1]**2)\n",
    "    x2.append(newFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.32112075e+02   2.13653648e-01  -4.78731119e-05]\n",
      "[ 0.49004374]\n"
     ]
    }
   ],
   "source": [
    "result2 = np.linalg.lstsq(x2,y)\n",
    "print result2[0]\n",
    "MSE2 = result2[1]/50000\n",
    "print MSE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x3 = []\n",
    "for feat in x1:\n",
    "    newFeat = feat[:]\n",
    "    newFeat.append(random.random())\n",
    "    x3.append(newFeat)\n",
    "result = np.linalg.lstsq(x3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49003053])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]/50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted coefficients $\\theta = [\\theta_0, \\theta_1,...]$ is:\n",
    "\n",
    "[  2.56420279e+02   1.35421303e-01  -1.72994866e+00   1.02651152e-01\n",
    "   1.09038568e-01  -2.76775146e-01   6.34332169e-03   3.85023977e-05\n",
    "  -2.58652809e+02   1.19540566e+00   8.33006285e-01   9.79304353e-02]\n",
    "\n",
    "And train data MSE is 0.6023075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE on the test data is 0.56245713031281874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('winequality-white.csv', 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    wine = []\n",
    "    for row in reader:\n",
    "        wine.append(row)\n",
    "for i in range(1,len(wine)):\n",
    "    for j in range(0,len(wine[i])):\n",
    "        wine[i][j] = float(wine[i][j])\n",
    "feature = wine[0]\n",
    "wine = wine[1:]\n",
    "train = np.array(wine[0:len(wine)/2])\n",
    "test = np.array(wine[len(wine)/2:len(wine)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = np.concatenate((np.ones((len(train),1)), train[:,0:-1]), axis=1)\n",
    "train_y = train[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.56420279e+02   1.35421303e-01  -1.72994866e+00   1.02651152e-01\n",
      "   1.09038568e-01  -2.76775146e-01   6.34332169e-03   3.85023977e-05\n",
      "  -2.58652809e+02   1.19540566e+00   8.33006285e-01   9.79304353e-02]\n",
      "[ 0.6023075]\n"
     ]
    }
   ],
   "source": [
    "result3 = np.linalg.lstsq(train_x,train_y)\n",
    "MSE3 = result3[1]/len(train)\n",
    "print result3[0]\n",
    "print MSE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = np.concatenate((np.ones((len(test),1)), test[:,0:-1]), axis=1)\n",
    "test_y = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562457130313\n"
     ]
    }
   ],
   "source": [
    "MSE_full = mean_squared_error(np.dot(test_x, result3[0]), test_y)\n",
    "print MSE_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Q4\n",
    "The MSEs of all 11 ablation experiments are calculated below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features with least and most information should be the ones have the smallest and largest increment based on MSE with full features(0.562457130313).\n",
    "\n",
    "Based on the test MSEs, we see 'density' provides the least additional information with smallest increment of -0.0177305768467\n",
    "\n",
    "While 'volatile acidity' provides the most information with largest increment of 0.0339277198487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE without the feature fixed acidity is 0.559113414376\n",
      "The difference with original MSE is -0.00334371593669\n",
      "\n",
      "The MSE without the feature volatile acidity is 0.596384850162\n",
      "The difference with original MSE is 0.0339277198487\n",
      "\n",
      "The MSE without the feature citric acid is 0.562221702812\n",
      "The difference with original MSE is -0.000235427501259\n",
      "\n",
      "The MSE without the feature residual sugar is 0.553625063967\n",
      "The difference with original MSE is -0.00883206634537\n",
      "\n",
      "The MSE without the feature chlorides is 0.562629266481\n",
      "The difference with original MSE is 0.000172136168481\n",
      "\n",
      "The MSE without the feature free sulfur dioxide is 0.55614081793\n",
      "The difference with original MSE is -0.00631631238286\n",
      "\n",
      "The MSE without the feature total sulfur dioxide is 0.562429005469\n",
      "The difference with original MSE is -2.81248436144e-05\n",
      "\n",
      "The MSE without the feature density is 0.544726553466\n",
      "The difference with original MSE is -0.0177305768467\n",
      "\n",
      "The MSE without the feature pH is 0.559566626382\n",
      "The difference with original MSE is -0.00289050393082\n",
      "\n",
      "The MSE without the feature sulphates is 0.557346349988\n",
      "The difference with original MSE is -0.00511078032493\n",
      "\n",
      "The MSE without the feature alcohol is 0.573214743558\n",
      "The difference with original MSE is 0.0107576132454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MSE_abl = []\n",
    "for i in range(1,12):\n",
    "    # get ablation feature data\n",
    "    train_abl = np.delete(train_x, i, axis=1)\n",
    "    test_abl = np.delete(test_x, i, axis=1)\n",
    "    # training\n",
    "    fit = np.linalg.lstsq(train_abl,train_y)\n",
    "    # mse\n",
    "    MSE_abl.append(mean_squared_error(np.dot(test_abl, fit[0]), test_y))\n",
    "for i in range(0,len(MSE_abl)):\n",
    "    print \"The MSE without the feature\", feature[i], \"is\", MSE_abl[i]\n",
    "    print \"The difference with original MSE is\", MSE_abl[i] - MSE_full\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under C=0.8, I have accuracy on train and test data as 89.91% and 69.86%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_lab = map(lambda x : 1 if x>5 else 0, train_y)\n",
    "test_lab = map(lambda x : 1 if x>5 else 0, test_y)\n",
    "clf = svm.SVC(C=0.8)\n",
    "clf.fit(train_x, train_lab)\n",
    "\n",
    "# prediction with classifier\n",
    "train_pred = clf.predict(train_x)\n",
    "test_pred = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pair = np.vstack((np.array(train_lab), train_pred))\n",
    "test_pair = np.vstack((np.array(test_lab), test_pred))\n",
    "train_correct = filter(lambda x : x[0] == x[1], train_pair.T)\n",
    "test_correct = filter(lambda x : x[0] == x[1], test_pair.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899142507146 0.698652511229\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = len(train_correct) * 1. /len(train_x)\n",
    "test_accuracy = len(test_correct) * 1. /len(test_x)\n",
    "print train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-likelihood after convergence is -1383.18, and the accuract of the resulting model is 76.68%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "    loglikelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        loglikelihood -= log(1 + exp(-logit))\n",
    "        if not y[i]:\n",
    "            loglikelihood -= logit\n",
    "    for k in range(len(theta)):\n",
    "        loglikelihood -= lam * theta[k]*theta[k]\n",
    "    return -loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "    dl = [0.0]*len(theta)\n",
    "    for i in range(len(X)):\n",
    "        xi = sigmoid(inner(X[i], theta))\n",
    "    # Fill in code for the derivative\n",
    "        for j in range(len(dl)):\n",
    "            dl[j] += X[i][j] * (1.0 - xi)\n",
    "            if not y[i]:\n",
    "                dl[j] -= X[i][j]\n",
    "    dl -= lam * 2.0 * theta\n",
    "    # Negate the return value since we're doing gradient *ascent*\n",
    "    return np.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final log likelihood = -1383.18543063\n",
      "Accuracy =  0.766843609637\n"
     ]
    }
   ],
   "source": [
    "# If we wanted to split with a validation set:\n",
    "#X_valid = X[len(X)/2:3*len(X)/4]\n",
    "#X_test = X[3*len(X)/4:]\n",
    "\n",
    "# Use a library function to run gradient descent (or you can implement yourself!)\n",
    "theta,l,info = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(train_x[0]), fprime, args = (train_x, train_lab, 1.0))\n",
    "print \"Final log likelihood =\", -l\n",
    "# predict the test data\n",
    "test_pred = map(lambda x: 0 if x<0.5 else 1, [sigmoid(inner(X, theta)) for X in test_x])\n",
    "test_pair = np.vstack((np.array(test_lab), test_pred))\n",
    "test_correct = filter(lambda x: x[0] == x[1], test_pair.T)\n",
    "print \"Accuracy = \", len(test_correct) * 1.0 / len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
