{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print \"Reading data...\"\n",
    "dataFile = open(\"/home/jmcauley/Downloads/winequality-white.csv\")\n",
    "header = dataFile.readline()\n",
    "fields = [\"constant\"] + header.strip().replace('\"','').split(';')\n",
    "featureNames = fields[:-1]\n",
    "labelName = fields[-1]\n",
    "lines = [[1.0] + [float(x) for x in l.split(';')] for l in dataFile]\n",
    "X = [l[:-1] for l in lines]\n",
    "y = [l[-1] > 5 for l in lines]\n",
    "print \"done\"\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print \"ll =\", loglikelihood\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "X_train = X[:int(len(X)/3)]\n",
    "y_train = y[:int(len(y)/3)]\n",
    "X_validate = X[int(len(X)/3):int(2*len(X)/3)]\n",
    "y_validate = y[int(len(y)/3):int(2*len(y)/3)]\n",
    "X_test = X[int(2*len(X)/3):]\n",
    "y_test = y[int(2*len(X)/3):]\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta):\n",
    "  scores_train = [inner(theta,x) for x in X_train]\n",
    "  scores_validate = [inner(theta,x) for x in X_validate]\n",
    "  scores_test = [inner(theta,x) for x in X_test]\n",
    "\n",
    "  predictions_train = [s > 0 for s in scores_train]\n",
    "  predictions_validate = [s > 0 for s in scores_validate]\n",
    "  predictions_test = [s > 0 for s in scores_test]\n",
    "\n",
    "  correct_train = [(a==b) for (a,b) in zip(predictions_train,y_train)]\n",
    "  correct_validate = [(a==b) for (a,b) in zip(predictions_validate,y_validate)]\n",
    "  correct_test = [(a==b) for (a,b) in zip(predictions_test,y_test)]\n",
    "  \n",
    "  acc_train = sum(correct_train) * 1.0 / len(correct_train)\n",
    "  acc_validate = sum(correct_validate) * 1.0 / len(correct_validate)\n",
    "  acc_test = sum(correct_test) * 1.0 / len(correct_test)\n",
    "  return acc_train, acc_validate, acc_test\n",
    "\n",
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "for lam in [0, 0.01, 1.0, 100.0]:\n",
    "  theta = train(lam)\n",
    "  acc_train, acc_validate, acc_test = performance(theta)\n",
    "  print(\"lambda = \" + str(lam) + \";\\ttrain=\" + str(acc_train) + \"; validate=\" + str(acc_validate) + \"; test=\" + str(acc_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
